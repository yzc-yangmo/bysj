{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models \n",
    "\n",
    "# ----\n",
    "from data.dataset import FoodImageDataset\n",
    "import custom_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame({\"filename\":os.listdir(\"../../train\")})\n",
    "df_val = pd.DataFrame({\"filename\":os.listdir(\"../../val\")})\n",
    "\n",
    "def get_class(filename):\n",
    "    info = filename.split(\"-\")\n",
    "    return info[1]\n",
    "\n",
    "df_train[\"class\"] = df_train[\"filename\"].apply(lambda x: get_class(x))\n",
    "df_val[\"class\"] = df_val[\"filename\"].apply(lambda x: get_class(x))\n",
    "\n",
    "\n",
    "\n",
    "names = []\n",
    "for i in df_val[\"class\"].unique(): \n",
    "    if i not in df_train[\"class\"].unique():\n",
    "        names.append(i)\n",
    "\n",
    "print(len(names))\n",
    "\n",
    "df_val[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# 配置日志\n",
    "logging.basicConfig(\n",
    "    filename=f'training_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# 记录超参数\n",
    "params = {\n",
    "    'batch_size': 32,\n",
    "    'lr': 0.001,\n",
    "    'epochs': 10\n",
    "}\n",
    "logging.info(f\"Hyperparameters: {params}\")\n",
    "\n",
    "# 模拟训练循环\n",
    "for epoch in range(params['epochs']):\n",
    "    train_loss = 0.1 * (0.9 ** epoch)  # 示例损失\n",
    "    val_loss = 0.2 * (0.9 ** epoch)\n",
    "    logging.info(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"file_name\": os.listdir(\"../../val\")})\n",
    "\n",
    "def process(file_name):\n",
    "    info = file_name.split(\"-\")\n",
    "    return info[1] if len(info) == 3 else info\n",
    "df['class'] = df['file_name'].apply(lambda x: process(x))\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open('./config.json'))\n",
    "mapping = json.load(open('./mapping.json'))\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_foodimages = FoodImageDataset(config[\"dataset\"][\"train_path\"])\n",
    "val_foodimages = FoodImageDataset(config[\"dataset\"][\"val_path\"])\n",
    "train_loader = DataLoader(train_foodimages, batch_size=config[\"train\"][\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_foodimages, batch_size=config[\"train\"][\"batch_size\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数\n",
    "def train_model(model, train_loader, val_loader):\n",
    "    # 根据配置文件定义超参数\n",
    "    lr = config[\"train\"][\"lr\"]\n",
    "    num_epochs = config[\"train\"][\"num_epochs\"]\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"using {device}\")\n",
    "    \n",
    "    # 移动模型到指定设备\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # 定义损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # 前向传播\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # 统计\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels.max(1)[1]).sum().item()\n",
    "        \n",
    "        train_acc = 100. * train_correct / train_total\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_acc = 100. * val_correct / val_total\n",
    "        \n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        \n",
    "        # 打印训练信息\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        print(f'Train Loss: {train_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        print('--------------------')\n",
    "        \n",
    "model = custom_models.FRM_20250213_1()\n",
    "train_model(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "config = json.load(open('./config.json'))\n",
    "\n",
    "for k, v in config.items():\n",
    "    print(k)\n",
    "    for kk, vv in v.items():\n",
    "        print(f\"--{kk}: {vv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from IPython.display import Image as ipython_Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_img_path = \"../dataset/train\"\n",
    "\n",
    "test_img_path = os.path.join(train_img_path, os.listdir(train_img_path)[0])\n",
    "\n",
    "\n",
    "\n",
    "ipython_Image(filename=test_img_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(test_img_path).convert('RGB')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                transforms.Resize((256, 256)),\n",
    "            ])\n",
    "new_img = transform(Image.open(test_img_path))\n",
    "\n",
    "new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "config = json.load(open('./config.json'))\n",
    "\n",
    "\n",
    "dict(zip(set(i.split(\"-\")[1] for i in os.listdir(config[\"dataset\"][\"train_path\"])), range(config[\"model\"][\"num_classes\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(i.split(\"-\")[1] for i in os.listdir(config[\"dataset\"][\"train_path\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "config = json.load(open('./config.json'))\n",
    "\n",
    "if not config[\"train\"][\"use_wandb\"]:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "from PIL import Image\n",
    "\n",
    "config = json.load(open('./config.json'))\n",
    "\n",
    "display_num = 100\n",
    "img_path = config[\"dataset\"][\"train_path\"]\n",
    "for i in os.listdir(img_path):\n",
    "    if display_num == 0:\n",
    "        break\n",
    "    display_num -= 1\n",
    "    print(Image.open(os.path.join(img_path, i)).size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "origin = json.load(open('./temp.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # 获取当前使用的 GPU 设备编号\n",
    "    current_device = torch.cuda.current_device()\n",
    "    # 获取该 GPU 的具体型号\n",
    "    gpu_name = torch.cuda.get_device_name(current_device)\n",
    "    print(f\"当前正在使用的 GPU 型号是: {gpu_name}\")\n",
    "else:\n",
    "    print(\"当前没有可用的 GPU，正在使用 CPU 进行推理。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time\n",
    "import torch\n",
    "from PIL import Image\n",
    "from data.transform import FoodImageTransform\n",
    "from model import Model\n",
    "config = json.load(open(\"config.json\", \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "model_state_path = \"./vit_128_0.0001_0.2_DA-2-20250330143538-best_model.pth\"\n",
    "\n",
    "# 加载模型\n",
    "model = Model(config[\"inference\"][\"name\"]).get_model()\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 读取模型参数\n",
    "if not os.path.exists(model_state_path):\n",
    "    raise FileNotFoundError(f\"not found model state file: {model_state_path}\")\n",
    "\n",
    "state_dict = torch.load(model_state_path, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(image_path):\n",
    "    start_time = time.time()\n",
    "    # 加载图像\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    # 图像预处理\n",
    "    image_tensor = FoodImageTransform(transform_type=0)(image).unsqueeze(0).to(device)# 添加批次维度并移动到GPU\n",
    "\n",
    "    # 推理\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)[0]\n",
    "        \n",
    "    # 获取最可能类别的索引和置信度\n",
    "    confidence, class_idx = torch.max(probabilities, 0)\n",
    "    confidence_value = confidence.item() * 100\n",
    "    print(f\"time: {time.time() - start_time:.2f} s, class_idx: {class_idx.item()}, confidence_value: {(confidence_value):.2f}%\")\n",
    "\n",
    "val_dir = config[\"train\"][\"dataset\"][\"val_path\"]\n",
    "for loc, i in enumerate(os.listdir(val_dir)):\n",
    "    print(f\"[{loc}/{len(os.listdir(val_dir))}] file name: {i}\", end=\" \")\n",
    "    inference(os.path.join(val_dir, i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.load(open(\"food-info.json\", \"r\", encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from InferenceEngine import InferenceEngine\n",
    "\n",
    "InferenceEngine = InferenceEngine()\n",
    "\n",
    "\n",
    "def work(target_dir, key):\n",
    "    count = 0 # 计数\n",
    "    \n",
    "    total = len(os.listdir(target_dir))\n",
    "    info_dict = {\"file_name\":[],\n",
    "                \"food_name\":[],\n",
    "                \"confidence\":[]}   \n",
    "    for i in tqdm(os.listdir(target_dir)):\n",
    "        if i.endswith(\".jpg\"):\n",
    "            infer_info = InferenceEngine.inference(os.path.join(target_dir, i))\n",
    "            info_dict[\"file_name\"].append(i)\n",
    "            info_dict[\"food_name\"].append(infer_info[\"food_name\"])\n",
    "            info_dict[\"confidence\"].append(infer_info[\"confidence\"])\n",
    "            \n",
    "            if int(infer_info[\"confidence\"]) < key:\n",
    "                count += 1\n",
    "    print(f\"The number of inference's confience is {count} ({count/total*100:.2f})%\")\n",
    "    csv_path = f\"./{target_dir.split(\"/\")[-1]}-analysis.csv\"\n",
    "    pd.DataFrame(info_dict).to_csv(csv_path, index=False)\n",
    "    print(f\"csv file saved: {csv_path}\")\n",
    "\n",
    "train_dir = \"../dataset/train-256\"\n",
    "val_dir = \"../dataset/val-256\"\n",
    "    \n",
    "work(train_dir, 50)\n",
    "work(val_dir, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import shutil, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = pd.read_csv(\"./train-256-analysis.csv\")\n",
    "train_info['label'] = train_info[\"file_name\"].apply(lambda x: x.split(\"-\")[1])\n",
    "train_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info[train_info[\"confidence\"] < 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_info[train_info[\"confidence\"] < 70].value_counts(\"label\").reset_index()\n",
    "temp[\"label\"] = temp[\"label\"].astype(int)\n",
    "temp = temp.sort_values(\"label\")\n",
    "\n",
    "plt.bar(temp[\"label\"], temp[\"count\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img-0-0001.jpg\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir(origin_dir):\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_dir = \"../dataset/train-256\"\n",
    "target_dir = \"../dataset/new-train-256\"\n",
    "\n",
    "exclude = train_info[train_info[\"confidence\"] < 70][\"file_name\"].to_list()\n",
    "\n",
    "for i in os.listdir(origin_dir):\n",
    "    if i.endswith(\".jpg\") and i not in exclude:\n",
    "        shutil.copy(os.path.join(origin_dir, i),\n",
    "                    os.path.join(target_dir, i))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_info = pd.read_csv(\"./val-256-analysis.csv\")\n",
    "val_info['label'] = val_info[\"file_name\"].apply(lambda x: x.split(\"-\")[1])\n",
    "val_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = val_info[val_info[\"confidence\"] < 70].value_counts(\"label\").reset_index()\n",
    "temp[\"label\"] = temp[\"label\"].astype(int)\n",
    "temp = temp.sort_values(\"label\")\n",
    "\n",
    "plt.bar(temp[\"label\"], temp[\"count\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_dir = \"../dataset/val-256\"\n",
    "target_dir = \"../dataset/new-val-256\"\n",
    "\n",
    "\n",
    "for i in os.listdir(origin_dir):\n",
    "    if i.endswith(\".jpg\") and i not in val_info[val_info[\"confidence\"] < 70][\"file_name\"]:\n",
    "        shutil.copy(os.path.join(origin_dir, i),\n",
    "                    os.path.join(target_dir, i))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../dataset/new-train-256/\"\n",
    "val_dir = \"../dataset/new-val-256\"\n",
    "\n",
    "train_df = pd.DataFrame({\"file name\": list(os.listdir(train_dir))})\n",
    "val_df = pd.DataFrame({\"file name\":list(os.listdir(val_dir))})\n",
    "\n",
    "train_df['class'] = train_df[\"file name\"].apply(lambda x: x.split(\"-\")[1])\n",
    "val_df['class'] = val_df[\"file name\"].apply(lambda x: x.split(\"-\")[1])\n",
    "\n",
    "train_info = train_df.value_counts(\"class\").reset_index()\n",
    "val_info = val_df.value_counts(\"class\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
